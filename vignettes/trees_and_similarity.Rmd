---
title: "trees_and_similarity"
author:
  - name: Paul Kruse
  - affiliation: United States Environmental Protection Agency
  - email: kruse.paul@epa.gov
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{trees_and_similarity}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
#library(treecompareR)
```

We begin this discussion on trees and similarity by covering a few basic ideas about trees and similarity measures.

A graph is a pair $(V, E)$ where $V$ denotes a set of vertices and $E$ denotes a set of edges. In the following, we are only considering undirected graphs, so we may view each edge as an unordered pair of two vertices. A tree is a connected graph that is acyclic. For each pair of vertices $v_i$ and $v_j$, there is a sequence of edges $e_{i_1}, \dots , e_{i_k}$ connecting the vertices. Moreover, since the graph is acyclic, there is a single unique path between any pair of distinct vertices. We denote by $|V|$ and $|E|$ the number of vertices and edges, respectively. It is a fact that for a tree with $n$ vertices, $|V| = n$, the number of edges is $n-1$, $|E| = n-1$. 

A tree may or may not have a specific vertex denoted as a root. In this discussion, we will consider trees with a root, and the root will be attached to two vertices. The degree of a vertex is the number of vertices directly connected to it by edges. The root in the trees we are considering has degree 2. The vertices that have degree 1 are called tips or leaves. 

To illustrate an example of a tree, we display below a rooted tree with 8 tips. We use ggtree to display the tree, and label the vertices.

```{r}
tip_8 <- treecompareR::generate_topology(n = 8, rooted = TRUE, seed = 42)
tip_8_visual <- ggtree(tip_8) + layout_circular() + geom_tiplab() + geom_nodelab()
tip_8_visual
```
Observe that there are 8 tips, labeled t1,..., t8, with the root labelled n1, and two additional internal nodes n2 and n3. The package ggtree allows for a variety of layouts and in this example we used the layout_circular() mode.

Also, observe that the tree `tip_8` is an object of class `phylo`.

```{r}
str(tip_8)
```
The edge table has two columns, with each row giving a pair of vertices that represent an edge. The root is given by the first node in the node.label list. Numbering of nodes for `phylo` objects starts with the tips and then the nodes, with the root at the beginning of the node numbering for rooted trees.

In a rooted tree, we may refer to the depth of a node, which is just the length of the path from the root to the node. We can visualize it in the following diagram with the root at the left, the tips at the right, and intermediary nodes in between.

```{r}
ggtree(tip_8) + theme_tree2() + geom_tiplab() + geom_nodelab() 
```


## Similarity measures


If we want to compare the nodes for a given tree, there are a variety of methods to do so. We can first consider the set of paths the root to each each node and examine these. We first look at one method that examines the edges of the tree.

# Jaccard similarity

For instance, consider tips `t5` and `t8`. The root-to-node path for `t5` consists of nodes $\{\text{n1, n2, n3, t5}\}$ and the root-to-node path for `t8` consists of nodes $\{\text{n1, n2, t8}\}$. The shared portion of the path is given by the nodes $\{\text{n1, n2}\}$. The lengths of these paths are 3, 2, and 1, respectively. We can relate these in the following expression $\text{sim}_{\text{Jac}}(v_1, v_2) = \frac{|l(mrca(v_1, v_2))|}{l(v_1) + l(v_2) - l(mrca(v_1, v_2))}$ where $l(v_i)$ denotes the length of the root-to-node path for node $v_i$ and $mrca(v_i, v_j)$ denotes most recent common ancestor for nodes $v_i$ and $v_j$, the shared vertex in the root-to-nodes paths for nodes $v_i$ and $v_j$ furthest from the root (and in some cases possibly the root). In the case of `t5` and `t8`, $\text{sim}_{\text{Jac}}(\text{t5, t8}) = \frac{1}{3 + 2 - 1} = \frac{1}{4}$. This notion of similarity is known as Jaccard similarity, and the function `general_Jaccard_similarity` takes as parameters a tree and two labels and returns the Jaccard similarity of the two labels within the tree. We exclude the case when the root is one of the nodes being compared. Note, if $v_i = v_j$, then $\text{sim}_{\text{Jac}}(v_i, v_j) = 1$.

```{r}
general_Jaccard_similarity(tip_8, 't5', 't8')
```
If we would like to determine the Jaccard similarity for each pair of nodes, we can generate a matrix of similarity values. The matrix is symmetric as $\text{sim}_{\text{Jac}}(v_i, v_j) = \text{sim}_{\text{Jac}}(v_j, v_i)$. To generate such a matrix, we use the function `generate_similarity_matrix()` which takes a tree and a similarity function as parameters.

```{r}
tip_8_Jaccard_sim <- generate_similarity_matrix(tip_8, similarity = general_Jaccard_similarity)
tip_8_Jaccard_sim
```
This method relates the lengths of the paths of both vertices from the root with the length of the path of their most recent common ancestor to the root. However, it does not take into account any information on the number of children or descendants either vertex has. So a pair of vertices that are tips and a pair of vertices that are internal nodes with several descendants may end up having the same level of similarity as defined by this method. To take into account such node-specific information, we introduce the notion of information content.

# Information Content

Some trees may come with a probability distribution attaching probabilities to each node such that the sum of all node probabilities is 1. In the case that a tree does not have such a distribution, we can still derive a node-specific value for each node in the tree. In fact, we can look at the number of descendants a node has and compare this with the total number of nodes in the tree. We would also like for tips to have a higher value than their ancestors, with the root having the minimum value. One way we can do this is by taking the ratio of number of nodes in a given subtree with a specified node as the root of the subtree with the total number of nodes and then evaluating a monotonically decreasing function on this. In particular, for node $v_i$, define $\text{IC}{v_i} = 1 - \frac{\log(1 + |\text{V}_{v_i}|)}{log(|V|)}$ where $V_{v_i}$ denotes the number of descendants of node $v_i$ and $|V|$ is the total number of nodes in the tree. In the case that $v_i$ is a leaf it has no descendants, so $\text{IC}(v_i) = 1 - \frac{\log(1)}{\log(|V|)} = 1$. If $v_i$ is the root, then $\text{IC}(v_i) = 1 - \frac{log(1 + |\text{V}_{v_i})}{\log(|V|)} = 1 - \frac{\log(|V|)}{\log(|V|)} = 0$. Also note that if $v_i$ is an ancestor of $v_j$, then $|\text{V}_{v_i}| > |\text{v_j}|$ and since the function $f(x) = 1 - \frac{1 + x}{N}$ (for $N > 0$) is monotonically decreasing for $x > 0$, it follows that $\text{IC}(v_i) < \text{IC}(v_j)$. Hence, the function above fits the desired properties. 

One way to frame the concept of information content is the idea that the less likely a node appears in a generic path starting from the root and ending at an arbitrary node, the more information it tells when we know the node is one a path given to us. So for instance, the only path a tip can exist on is the unique path connecting it with the root. However, for an ancestor of a tip, there are more paths that include this node, so knowing the ancestor is on a path gives less information about what the path might be. Since every path starting at the root includes the root, knowing the root is on the path yields no information.

To generate the information content for a tree, we can use the function `attach_information_content()` which takes in a tree as the only required parameter.

```{r}
tip_8 <- attach_information_content(tip_8)
tip_8$IC
```
This function also includes the number of descendants, children, and the level for each node. Observe that all of the tips have 0 descendants and an information content of 1, given by the `log_descendants` column. The root has an information content of 0. The remaining two nodes have the desired inequality in the values of their information content.
